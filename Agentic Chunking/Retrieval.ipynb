{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain import hub\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:11434/v1\"\n",
    "#os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4-1106-preview\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model='llama3')\n",
    "prompt = hub.pull(\"ritwik/propositional-indexing\")\n",
    "\n",
    "'''class Proposition(BaseModel):\n",
    "    \"Returns a list of sentences from json-esque string.\"\n",
    "    sentence: List[str] = Field(description=\"Append sentences within double quotations into a list\")\n",
    "\n",
    "#class Data(BaseModel):\n",
    "Sentences: List[Proposition]'''\n",
    "\n",
    "#parser = PydanticOutputParser(pydantic_object=Proposition)\n",
    "#print(parser.get_format_instructions())\n",
    "\n",
    "runnable = prompt | llm   #runnable to combine the chain -> returns  str(json-esque structure)\n",
    "\n",
    "#Converts LLM generated json-esque string of propositions -> List of strings(propositions)\n",
    "def extract_propositions(text) -> List:\n",
    "\n",
    "    pattern = re.compile(r'\\[(.*?)\\]', re.DOTALL)\n",
    "    match = pattern.search(text)\n",
    "    content = match.group(1)\n",
    "    propositions = []\n",
    "\n",
    "    for itm in content.split(','):\n",
    "        sentence =itm.strip().strip('\"') \n",
    "        propositions.append(sentence)\n",
    "        \n",
    "    return propositions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "node_parser = SentenceSplitter(chunk_size=256, chunk_overlap=0)\n",
    "\n",
    "doc_pages = SimpleDirectoryReader(input_dir=\"/home/ritwik-gosh/Fine_tuning/data/\", exclude=[\"ACA.pdf\"]).load_data()\n",
    "#print(doc[1].page_content)\n",
    "\n",
    "\n",
    "chunks = node_parser.get_nodes_from_documents(doc_pages)\n",
    "'''for idx in range(len(doc_pages)):\n",
    "    page_content = doc_pages[idx].text\n",
    "    rec_chunks.extend(node_parser.get_nodes_from_documents([page_content]))'''\n",
    "\n",
    "    #single_sentences_list.append(re.split(r'(?<=[.?!])\\s+', page_content))\n",
    "\n",
    "all_props = []\n",
    "for idx in range(1):\n",
    "    chunk = chunks[idx].text\n",
    "    runnable_output = runnable.invoke({\"input\": chunk}).content\n",
    "    all_props.extend(extract_propositions(runnable_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nedyalko Peshev', 'Valentin Tsenev investigated the effect of solder material quantity on obtaining strong solder joints in LGA type assembly.', 'The researchers analyzed results of their research on the strength of solders of LGA (Land Grid Array) assembly type at different amounts of soldering material and using Hot bar soldering technology.', 'Experiments were described for achieving the maximum tensile strength of soldered pads on a flexible circuit board (FPC) to a standard rigid circuit board (PCB) at different amounts of solder by Hot bar soldering.', 'The method of measuring the amount of solder material was specified and the setup for measuring solder height was described.', 'The soldering system of flexible and rigid board was applied', 'and the studied pads were described.']\n"
     ]
    }
   ],
   "source": [
    "print(all_props)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the decomposed list of propositions:\n",
      "\n",
      "[\"Harper's parent is a person called Mr. Bane.\", \n",
      "\"Mr. Bane is Harper's father.\",\n",
      "\"Harper did not recognize Mr. Bane as her parent until her first birthday.\", \n",
      "\"It is surprising that this is the case.\", \n",
      "\"The situation is unusual.\"]"
     ]
    }
   ],
   "source": [
    "paragh = \"Harper was the daughter of Mr. Bane who she never recognised until her first birthday.It is astonishingly weird.\"\n",
    "\n",
    "for chunk in runnable.stream({\"input\": paragh}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Extraction\\nextraction_chain = create_extraction_chain_pydantic(pydantic_schema=Sentences, llm=llm)\\npropositions = extraction_chain.run(out).sentences'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pydantic data class\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    '''\n",
    "    This class is used to extract the sentences from the output of an LLM and store them one-by-one into a list.\n",
    "    '''\n",
    "    sentences: List[str]\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Sentences)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    \n",
    "'''# Extraction\n",
    "extraction_chain = create_extraction_chain_pydantic(pydantic_schema=Sentences, llm=llm)\n",
    "propositions = extraction_chain.run(out).sentences'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"This class is used to extract the sentences from the output of an LLM and store them one-by-one into a list.\", \"properties\": {\"sentences\": {\"title\": \"Sentences\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"sentences\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
